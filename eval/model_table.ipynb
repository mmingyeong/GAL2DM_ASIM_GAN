{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf8b568f",
   "metadata": {},
   "source": [
    "### 4. Model Complexity & Practical Usability (모델 복잡도 및 실용성)\n",
    "\n",
    "이 표는 각 모델이 **얼마나 계산적으로 무거운지**, 그리고 실제 사용할 때 **연산/메모리 비용**이 어느 정도인지 비교합니다.\n",
    "\n",
    "| Metric | 의미 (Korean 설명) |\n",
    "|-------|----------------|\n",
    "| **Params (#)** | 학습 가능한 파라미터 총 개수. 모델 표현력 규모를 반영하나, 너무 크면 과적합 및 메모리 비용 증가 가능. |\n",
    "| **FLOPs** | 단일 추론(Forward pass) 동안 수행되는 부동소수점 연산 수. 연산 복잡도의 직접적인 척도. |\n",
    "| **Inference Memory (MB)** | 입력 1개를 추론할 때 GPU 메모리가 어느 정도 사용되는지. |\n",
    "| **Latency per Inference (s)** | 입력 하나를 처리하는 데 걸리는 시간. 실시간 처리 가능성 및 배치 사이즈 결정에 영향. |\n",
    "\n",
    "#### 해석 관점\n",
    "- **ViT** 계열은 일반적으로 **파라미터 수는 크지만 FLOPs 효율이 좋아** 추론 속도는 빠른 편.\n",
    "- **UNet3D (V-NET)** 는 **입체 convolution 핵심 구조로 인해 메모리 사용량이 크고 추론 시간이 상대적으로 길 수 있음.**\n",
    "- **Base Model** 은 구조가 단순하므로 일반적으로 가장 가볍지만 성능 한계가 존재.\n",
    "\n",
    "즉,\n",
    "> 이 표는 “**정확도 vs 계산비용**” 트레이드오프를 정량적으로 보여주며,  \n",
    "> 실제 운용 환경에서 어떤 모델을 선택해야 하는지를 결정하는 핵심 기준이 됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105bbea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 15:18:23.727498: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-12 15:18:34.655507: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# <<< 이 셀을 노트북 \"맨 위\"에서 실행하세요 >>>\n",
    "import os\n",
    "# TF가 GPU를 전혀 보지 못하도록 비활성화 (CPU 강제)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "# GPU가 안 보이므로 굳이 메모리 그로스 설정은 불필요\n",
    "\n",
    "# PyTorch는 별도 환경에서 GPU 사용 (CUDA_VISIBLE_DEVICES가 빈 문자열이면 CPU만 보임)\n",
    "# -> Torch쪽에서는 다시 원하는 GPU를 지정해서 사용하세요 (SLURM 스크립트 등에서 지정)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c1d0c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Choose a big GPU (e.g., 1) BEFORE importing TF/Torch =====\n",
    "import os\n",
    "GPU_ID = \"1\"  # <- 20GB 있는 GPU로 지정 (원하면 \"2\",\"3\"로 바꿔도 됨)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU_ID\n",
    "os.environ.setdefault(\"TF_GPU_ALLOCATOR\", \"cuda_malloc_async\")  # TF 메모리 파편화 완화\n",
    "\n",
    "# (이 아래부터 TensorFlow / PyTorch import)\n",
    "import tensorflow as tf\n",
    "\n",
    "# Enable memory growth on visible GPUs\n",
    "try:\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    for g in gpus:\n",
    "        tf.config.experimental.set_memory_growth(g, True)\n",
    "    TF_DEVICE = \"/GPU:0\" if gpus else \"/CPU:0\"   # CUDA_VISIBLE_DEVICES로 remap된 0번\n",
    "except Exception:\n",
    "    TF_DEVICE = \"/CPU:0\"\n",
    "\n",
    "import torch\n",
    "TORCH_DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"  # 동일하게 remap된 0\n",
    "\n",
    "# ----- TF latency/memory (GPU/CPU 자동) -----\n",
    "def tf_infer_latency_and_memory(model, input_shape=(1,2,128,128,128), warmup=2, runs=5):\n",
    "    x = tf.random.normal(input_shape, dtype=tf.float32)\n",
    "    call_fn = tf.function(model, jit_compile=False)\n",
    "    # Warmup\n",
    "    for _ in range(warmup):\n",
    "        _ = call_fn(x, training=False)\n",
    "\n",
    "    # Memory (best-effort)\n",
    "    mem_mb = float(\"nan\")\n",
    "    try:\n",
    "        info0 = tf.config.experimental.get_memory_info(\"GPU:0\")\n",
    "    except Exception:\n",
    "        info0 = None\n",
    "\n",
    "    t0 = tf.timestamp()\n",
    "    for _ in range(runs):\n",
    "        _ = call_fn(x, training=False)\n",
    "    t1 = tf.timestamp()\n",
    "\n",
    "    if info0 is not None:\n",
    "        try:\n",
    "            info1 = tf.config.experimental.get_memory_info(\"GPU:0\")\n",
    "            peak = max(info0.get(\"peak\", 0), info1.get(\"peak\", 0))\n",
    "            mem_mb = float(peak) / (1024**2)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return float(t1 - t0) / runs, mem_mb\n",
    "\n",
    "# ----- Torch latency/memory/FLOPs (동일한 logical cuda:0 사용) -----\n",
    "def torch_infer_latency(model, input_shape=(1,2,128,128,128), device=TORCH_DEVICE, warmup=3, runs=5):\n",
    "    model = model.to(device).eval()\n",
    "    x = torch.randn(*input_shape, device=device)\n",
    "    if device.startswith(\"cuda\"):\n",
    "        torch.cuda.synchronize()\n",
    "    with torch.inference_mode():\n",
    "        for _ in range(warmup):\n",
    "            _ = model(x)\n",
    "        if device.startswith(\"cuda\"):\n",
    "            torch.cuda.synchronize()\n",
    "        import time\n",
    "        t0 = time.time()\n",
    "        for _ in range(runs):\n",
    "            _ = model(x)\n",
    "        if device.startswith(\"cuda\"):\n",
    "            torch.cuda.synchronize()\n",
    "        t1 = time.time()\n",
    "    return float((t1 - t0) / runs)\n",
    "\n",
    "def torch_infer_memory(model, input_shape=(1,2,128,128,128), device=TORCH_DEVICE):\n",
    "    if not device.startswith(\"cuda\"):\n",
    "        return float(\"nan\")\n",
    "    model = model.to(device).eval()\n",
    "    x = torch.randn(*input_shape, device=device)\n",
    "    torch.cuda.reset_peak_memory_stats(device)\n",
    "    with torch.inference_mode():\n",
    "        _ = model(x)\n",
    "    return torch.cuda.max_memory_allocated(device) / (1024**2)\n",
    "\n",
    "try:\n",
    "    from thop import profile, clever_format\n",
    "    def torch_try_flops(model, input_shape=(1,2,128,128,128), device=TORCH_DEVICE):\n",
    "        model = model.to(device).eval()\n",
    "        x = torch.randn(*input_shape, device=device)\n",
    "        macs, _ = profile(model, inputs=(x,), verbose=False)\n",
    "        flops_val = macs * 2\n",
    "        flops_str, _ = clever_format([flops_val, macs], \"%.3f\")\n",
    "        return flops_str\n",
    "except Exception:\n",
    "    def torch_try_flops(*args, **kwargs):\n",
    "        return \"N/A\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82851c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Base model: <class 'keras.src.engine.functional.Functional'>\n",
      "✅ UNet3D: <class 'UNet3D_mod.UNet3D'>\n",
      "✅ ViT: <class 'VoxelViTUNet3D_mod.VoxelViTUNet3D'>\n",
      "✅ cGAN class: <class 'pix2pixcc3d.model.GeneratorPix2PixCC3D'>\n"
     ]
    }
   ],
   "source": [
    "# ===== Safe loaders =====\n",
    "import importlib.util, types, sys, os\n",
    "\n",
    "def load_symbol_from_file(py_path: str, symbol_name: str):\n",
    "    \"\"\"Simple loader for files WITHOUT relative imports.\"\"\"\n",
    "    spec = importlib.util.spec_from_file_location(f\"{symbol_name}_mod\", py_path)\n",
    "    if spec is None or spec.loader is None:\n",
    "        raise ImportError(f\"Cannot load spec for {py_path}\")\n",
    "    mod = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(mod)  # type: ignore\n",
    "    if not hasattr(mod, symbol_name):\n",
    "        raise ImportError(f\"{symbol_name} not found in {py_path}\")\n",
    "    return getattr(mod, symbol_name)\n",
    "\n",
    "def load_symbol_with_package(model_path: str, symbol_name: str, pkg: str = \"pix2pixcc3d\"):\n",
    "    \"\"\"\n",
    "    Loader for modules that use relative imports like `from .utils import ...`.\n",
    "    Loads <pkg>.utils and <pkg>.model so that `.utils` resolves.\n",
    "    \"\"\"\n",
    "    model_path = os.path.abspath(model_path)\n",
    "    src_dir    = os.path.dirname(model_path)\n",
    "    utils_path = os.path.join(src_dir, \"utils.py\")\n",
    "\n",
    "    if not os.path.isfile(model_path):\n",
    "        raise ImportError(f\"[cGAN] model file not found: {model_path}\")\n",
    "    if not os.path.isfile(utils_path):\n",
    "        raise ImportError(f\"[cGAN] utils file not found: {utils_path}\")\n",
    "\n",
    "    # Load <pkg>.utils\n",
    "    utils_name = f\"{pkg}.utils\"\n",
    "    if utils_name not in sys.modules:\n",
    "        utils_spec = importlib.util.spec_from_file_location(utils_name, utils_path)\n",
    "        if utils_spec is None or utils_spec.loader is None:\n",
    "            raise ImportError(f\"[cGAN] Cannot create spec for utils: {utils_path}\")\n",
    "        utils_mod = importlib.util.module_from_spec(utils_spec)\n",
    "        sys.modules[utils_name] = utils_mod\n",
    "        utils_spec.loader.exec_module(utils_mod)  # type: ignore\n",
    "\n",
    "    # Load <pkg>.model\n",
    "    model_name = f\"{pkg}.model\"\n",
    "    model_spec = importlib.util.spec_from_file_location(model_name, model_path)\n",
    "    if model_spec is None or model_spec.loader is None:\n",
    "        raise ImportError(f\"[cGAN] Cannot create spec for model: {model_path}\")\n",
    "    model_mod = importlib.util.module_from_spec(model_spec)\n",
    "    model_mod.__package__ = pkg  # <-- crucial for `.utils`\n",
    "    sys.modules[model_name] = model_mod\n",
    "    model_spec.loader.exec_module(model_mod)  # type: ignore\n",
    "\n",
    "    if not hasattr(model_mod, symbol_name):\n",
    "        raise ImportError(f\"[cGAN] {symbol_name} not found in {model_path}\")\n",
    "    return getattr(model_mod, symbol_name)\n",
    "\n",
    "# ===== Exact paths & class names =====\n",
    "BASE_PATH = \"/gpfs/adupuy/CF4_CNN/generatorSingle.py\"               # TF Generator()\n",
    "UNET_PATH = \"/home/mingyeong/GAL2DM_ASIM_VNET/src/model.py\"         # UNet3D\n",
    "VIT_PATH  = \"/home/mingyeong/GAL2DM_ASIM_ViT/src/model.py\"          # VoxelViTUNet3D\n",
    "GAN_PATH  = \"/home/mingyeong/GAL2DM_ASIM_GAN/src/model.py\"          # cGAN (uses .utils)\n",
    "\n",
    "SYM_BASE = \"Generator\"\n",
    "SYM_UNET = \"UNet3D\"\n",
    "SYM_VIT  = \"VoxelViTUNet3D\"\n",
    "SYM_GAN  = \"GeneratorPix2PixCC3D\"\n",
    "\n",
    "# ===== Load TensorFlow Base Model =====\n",
    "import tensorflow as tf\n",
    "Generator = load_symbol_from_file(BASE_PATH, SYM_BASE)\n",
    "base_model_tf = Generator()  # returns tf.keras.Model, input=(B,2,128,128,128)\n",
    "\n",
    "# ===== Load PyTorch models =====\n",
    "import torch\n",
    "UNet3D = load_symbol_from_file(UNET_PATH, SYM_UNET)\n",
    "VoxelViTUNet3D = load_symbol_from_file(VIT_PATH, SYM_VIT)\n",
    "# ⚠️ Do NOT overwrite GAN_PATH (string). Load the CLASS into a new name:\n",
    "GeneratorPix2PixCC3D = load_symbol_with_package(GAN_PATH, SYM_GAN, pkg=\"pix2pixcc3d\")\n",
    "\n",
    "# UNet3D uses in_ch, out_ch\n",
    "unet_model_torch = UNet3D(in_ch=2, out_ch=1)\n",
    "\n",
    "# VoxelViTUNet3D: try reasonable constructor signatures\n",
    "def instantiate_vit(cls):\n",
    "    try:\n",
    "        return cls(in_ch=2, out_ch=1)\n",
    "    except TypeError:\n",
    "        pass\n",
    "    try:\n",
    "        return cls(in_channels=2, out_channels=1)\n",
    "    except TypeError:\n",
    "        pass\n",
    "    return cls()  # fallback → internal defaults\n",
    "\n",
    "vit_model_torch = instantiate_vit(VoxelViTUNet3D)\n",
    "\n",
    "print(\"✅ Base model:\", type(base_model_tf))\n",
    "print(\"✅ UNet3D:\", type(unet_model_torch))\n",
    "print(\"✅ ViT:\", type(vit_model_torch))\n",
    "print(\"✅ cGAN class:\", GeneratorPix2PixCC3D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5795af07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating V-NET (UNet3D) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:mode trilinear is not implemented yet, take it a zero op\n",
      "WARNING:root:mode trilinear is not implemented yet, take it a zero op\n",
      "WARNING:root:mode trilinear is not implemented yet, take it a zero op\n",
      "WARNING:root:mode trilinear is not implemented yet, take it a zero op\n",
      "WARNING:root:mode trilinear is not implemented yet, take it a zero op\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating ViT (3D Transformer) ---\n",
      "\n",
      "=== Model Complexity & Practical Usability (PyTorch) ===\n",
      "\n",
      "               Model  Params (#)    FLOPs    MACs  Inference Memory (MB)  Latency per Inference (s)\n",
      "      V-NET (UNet3D)    28823577 121.235G 60.617G             854.778809                   0.030333\n",
      "ViT (3D Transformer)    23485633   2.282T  1.141T            3010.214355                   0.120250\n",
      "\n",
      "Saved → model_complexity_summary_torch.csv\n",
      "\n",
      "[TensorFlow] Base Model params: 461,006,711\n"
     ]
    }
   ],
   "source": [
    "# ==== Consistent names from your loaders/constructors ====\n",
    "# TensorFlow\n",
    "base_model_tf = base_model_tf      # already created above\n",
    "\n",
    "# PyTorch\n",
    "unet_model = unet_model_torch\n",
    "vit_model  = vit_model_torch\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "from thop import profile, clever_format  # pip install thop\n",
    "\n",
    "def count_params(model: torch.nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def _ensure_device(device: str) -> torch.device:\n",
    "    if device.startswith(\"cuda\"):\n",
    "        if not torch.cuda.is_available():\n",
    "            print(\"[WARN] CUDA requested but not available. Falling back to CPU.\")\n",
    "            return torch.device(\"cpu\")\n",
    "        # support e.g. \"cuda:0\"\n",
    "        return torch.device(device)\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "def measure_inference_memory(model: torch.nn.Module,\n",
    "                             input_shape=(1,2,128,128,128),\n",
    "                             device=\"cuda\") -> float:\n",
    "    dev = _ensure_device(device)\n",
    "    model = model.to(dev).eval()\n",
    "    dummy = torch.randn(*input_shape, device=dev)\n",
    "\n",
    "    if dev.type != \"cuda\":\n",
    "        return float(\"nan\")  # GPU-only metric\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats(dev)\n",
    "    with torch.no_grad():\n",
    "        _ = model(dummy)\n",
    "    return torch.cuda.max_memory_allocated(dev) / (1024**2)\n",
    "\n",
    "def measure_latency(model: torch.nn.Module,\n",
    "                    input_shape=(1,2,128,128,128),\n",
    "                    device=\"cuda\",\n",
    "                    warmup=3, runs=5) -> float:\n",
    "    dev = _ensure_device(device)\n",
    "    model = model.to(dev).eval()\n",
    "    dummy = torch.randn(*input_shape, device=dev)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(warmup):\n",
    "            _ = model(dummy)\n",
    "\n",
    "        if dev.type == \"cuda\":\n",
    "            torch.cuda.synchronize(dev)\n",
    "        t0 = time.time()\n",
    "        for _ in range(runs):\n",
    "            _ = model(dummy)\n",
    "        if dev.type == \"cuda\":\n",
    "            torch.cuda.synchronize(dev)\n",
    "\n",
    "    return (time.time() - t0) / runs\n",
    "\n",
    "def evaluate_model_complexity(model_dict, input_shape=(1,2,128,128,128), device=\"cuda\"):\n",
    "    dev = _ensure_device(device)\n",
    "    results = []\n",
    "    for name, model in model_dict.items():\n",
    "        print(f\"\\n--- Evaluating {name} ---\")\n",
    "        # Params\n",
    "        try:\n",
    "            params = count_params(model)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Param count failed for {name}: {e}\")\n",
    "            params = float(\"nan\")\n",
    "\n",
    "        # FLOPs / MACs via thop (may fail for some custom layers)\n",
    "        try:\n",
    "            dummy = torch.randn(*input_shape, device=dev)\n",
    "            model_eval = model.to(dev).eval()\n",
    "            macs_raw, _ = profile(model_eval, inputs=(dummy,), verbose=False)\n",
    "            # FLOPs ~= 2 * MACs is a common convention for convs\n",
    "            flops_str, macs_str = clever_format([macs_raw * 2, macs_raw], \"%.3f\")\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] THOP profiling failed for {name}: {e}\")\n",
    "            flops_str, macs_str = \"NaN\", \"NaN\"\n",
    "\n",
    "        # Inference memory (GPU only)\n",
    "        try:\n",
    "            mem = measure_inference_memory(model, input_shape, device)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Memory measurement failed for {name}: {e}\")\n",
    "            mem = float(\"nan\")\n",
    "\n",
    "        # Latency\n",
    "        try:\n",
    "            latency = measure_latency(model, input_shape, device)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Latency measurement failed for {name}: {e}\")\n",
    "            latency = float(\"nan\")\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"Params (#)\": params,\n",
    "            \"FLOPs\": flops_str,\n",
    "            \"MACs\": macs_str,\n",
    "            \"Inference Memory (MB)\": mem,\n",
    "            \"Latency per Inference (s)\": latency,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# --------------------- Run (PyTorch-only) ---------------------\n",
    "model_dict = {\n",
    "    \"V-NET (UNet3D)\": unet_model,\n",
    "    \"ViT (3D Transformer)\": vit_model,\n",
    "}\n",
    "df_complex = evaluate_model_complexity(model_dict, input_shape=(1,2,128,128,128), device=\"cuda\")\n",
    "\n",
    "print(\"\\n=== Model Complexity & Practical Usability (PyTorch) ===\\n\")\n",
    "print(df_complex.to_string(index=False))\n",
    "df_complex.to_csv(\"model_complexity_summary_torch.csv\", index=False)\n",
    "print(\"\\nSaved → model_complexity_summary_torch.csv\")\n",
    "\n",
    "# --------------------- Optional: TensorFlow base model summary ---------------------\n",
    "try:\n",
    "    # Keras parameter count (trainable + non-trainable)\n",
    "    tf_params = int(base_model_tf.count_params())\n",
    "    print(f\"\\n[TensorFlow] Base Model params: {tf_params:,}\")\n",
    "    # If you need TF FLOPs/latency, profile separately with tf.profiler or tf.function jit; not compatible with thop.\n",
    "except Exception as e:\n",
    "    print(f\"[WARN] TensorFlow base model summary failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74809b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:mode trilinear is not implemented yet, take it a zero op\n",
      "WARNING:root:mode trilinear is not implemented yet, take it a zero op\n",
      "WARNING:root:mode trilinear is not implemented yet, take it a zero op\n",
      "WARNING:root:mode trilinear is not implemented yet, take it a zero op\n",
      "WARNING:root:mode trilinear is not implemented yet, take it a zero op\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 15:22:26.562222: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2025-11-12 15:22:26.666930: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2025-11-12 15:22:26.678750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20533 MB memory:  -> device: 0, name: NVIDIA A10, pci bus id: 0000:48:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mingyeong/miniconda3/envs/torch/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:5232: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mingyeong/miniconda3/envs/torch/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:5232: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1839.50b flops)\n",
      "  model_1/conv3d_18/Conv3D (695.78b/695.78b flops)\n",
      "  model_1/conv3d_17/Conv3D (347.89b/347.89b flops)\n",
      "  model_1/conv3d_11/Conv3D (268.44b/268.44b flops)\n",
      "  model_1/conv3d_16/Conv3D (173.95b/173.95b flops)\n",
      "  model_1/conv3d_12/Conv3D (134.22b/134.22b flops)\n",
      "  model_1/conv3d_15/Conv3D (86.97b/86.97b flops)\n",
      "  model_1/conv3d_13/Conv3D (67.11b/67.11b flops)\n",
      "  model_1/conv3d_14/Conv3D (33.55b/33.55b flops)\n",
      "  model_1/conv3d_10/Conv3D (16.78b/16.78b flops)\n",
      "  model_1/conv3d_19/Conv3D (14.72b/14.72b flops)\n",
      "  model_1/conv3d_10/BiasAdd (33.55m/33.55m flops)\n",
      "  model_1/conv3d_18/BiasAdd (33.55m/33.55m flops)\n",
      "  model_1/conv3d_11/BiasAdd (8.39m/8.39m flops)\n",
      "  model_1/conv3d_17/BiasAdd (8.39m/8.39m flops)\n",
      "  model_1/conv3d_12/BiasAdd (2.10m/2.10m flops)\n",
      "  model_1/conv3d_16/BiasAdd (2.10m/2.10m flops)\n",
      "  model_1/conv3d_19/BiasAdd (2.10m/2.10m flops)\n",
      "  model_1/conv3d_13/BiasAdd (524.29k/524.29k flops)\n",
      "  model_1/conv3d_15/BiasAdd (524.29k/524.29k flops)\n",
      "  model_1/conv3d_14/BiasAdd (131.07k/131.07k flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 15:22:48.803943: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8905\n",
      "2025-11-12 15:22:48.888857: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Complexity & Practical Usability (All) ===\n",
      "\n",
      "               Model   Params    FLOPs    MACs        Mem    Latency\n",
      "      V-NET (UNet3D)  28.824M 121.235G 60.617G 937.386 MB  30.379 ms\n",
      "ViT (3D Transformer)  23.502M   2.282T  1.141T     2.994K 119.247 ms\n",
      "     Base Model (TF) 461.007M   1.840T     NaN     6.002K 246.976 ms\n",
      "\n",
      "Saved → model_complexity_summary_all.csv\n"
     ]
    }
   ],
   "source": [
    "import os, time, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from thop import profile, clever_format\n",
    "\n",
    "# ========= Unit formatters =========\n",
    "def fmt_si(x, kind=\"count\"):\n",
    "    if x is None or (isinstance(x, float) and (math.isnan(x) or math.isinf(x))):\n",
    "        return \"NaN\"\n",
    "    scales = [\n",
    "        (1e12, \"T\"),\n",
    "        (1e9,  \"G\"),\n",
    "        (1e6,  \"M\"),\n",
    "        (1e3,  \"K\"),\n",
    "    ]\n",
    "    for s, tag in scales:\n",
    "        if abs(x) >= s:\n",
    "            val = x / s\n",
    "            return f\"{val:.3f}{tag}\"\n",
    "    if kind == \"time_ms\":\n",
    "        return f\"{x*1e3:.3f} ms\"\n",
    "    if kind == \"mem\":\n",
    "        return f\"{x:.3f} MB\"\n",
    "    return f\"{x:.0f}\"\n",
    "\n",
    "def fmt_params(n):  # counts -> M/B\n",
    "    if n is None or (isinstance(n, float) and (math.isnan(n) or math.isinf(n))):\n",
    "        return \"NaN\"\n",
    "    if n >= 1e9:\n",
    "        return f\"{n/1e9:.3f}B\"\n",
    "    if n >= 1e6:\n",
    "        return f\"{n/1e6:.3f}M\"\n",
    "    return f\"{n:,}\"\n",
    "\n",
    "# ========= PyTorch profiling =========\n",
    "def _ensure_device(device: str) -> torch.device:\n",
    "    if device.startswith(\"cuda\"):\n",
    "        if not torch.cuda.is_available():\n",
    "            print(\"[WARN] CUDA requested but not available. Falling back to CPU.\")\n",
    "            return torch.device(\"cpu\")\n",
    "        return torch.device(device)\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "def torch_profile(model: torch.nn.Module,\n",
    "                  input_shape=(1,2,128,128,128),\n",
    "                  device=\"cuda\",\n",
    "                  warmup=3, runs=5):\n",
    "    dev = _ensure_device(device)\n",
    "    model = model.to(dev).eval()\n",
    "    x = torch.randn(*input_shape, device=dev)\n",
    "\n",
    "    # Params\n",
    "    try:\n",
    "        params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    except Exception:\n",
    "        params = float(\"nan\")\n",
    "\n",
    "    # FLOPs/MACs\n",
    "    try:\n",
    "        macs_raw, _ = profile(model, inputs=(x,), verbose=False)\n",
    "        flops_str, macs_str = clever_format([macs_raw * 2, macs_raw], \"%.3f\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] THOP failed: {e}\")\n",
    "        flops_str, macs_str = \"NaN\", \"NaN\"\n",
    "\n",
    "    # GPU mem\n",
    "    try:\n",
    "        if dev.type == \"cuda\":\n",
    "            torch.cuda.reset_peak_memory_stats(dev)\n",
    "            with torch.no_grad():\n",
    "                _ = model(x)\n",
    "            mem_mb = torch.cuda.max_memory_allocated(dev) / (1024**2)\n",
    "        else:\n",
    "            mem_mb = float(\"nan\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Torch mem failed: {e}\")\n",
    "        mem_mb = float(\"nan\")\n",
    "\n",
    "    # Latency\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            for _ in range(warmup):\n",
    "                _ = model(x)\n",
    "            if dev.type == \"cuda\":\n",
    "                torch.cuda.synchronize(dev)\n",
    "            t0 = time.time()\n",
    "            for _ in range(runs):\n",
    "                _ = model(x)\n",
    "            if dev.type == \"cuda\":\n",
    "                torch.cuda.synchronize(dev)\n",
    "        lat_s = (time.time() - t0) / runs\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Torch latency failed: {e}\")\n",
    "        lat_s = float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"Params (#)\": params,\n",
    "        \"FLOPs\": flops_str,\n",
    "        \"MACs\": macs_str,\n",
    "        \"Inference Memory (MB)\": mem_mb,\n",
    "        \"Latency per Inference (s)\": lat_s,\n",
    "    }\n",
    "\n",
    "# ========= TensorFlow profiling =========\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2_as_graph\n",
    "\n",
    "def _tf_input_shape_from_model(model, fallback=(1,128,128,128,2)):\n",
    "    try:\n",
    "        shp = model.input_shape\n",
    "        if isinstance(shp, (list, tuple)):\n",
    "            if isinstance(shp[0], (list, tuple)):  # multiple inputs\n",
    "                shp = shp[0]\n",
    "        # replace None batch with 1\n",
    "        shp = tuple(1 if (d is None) else d for d in shp)\n",
    "        if len(shp) == 5:\n",
    "            return shp  # assume model is correct (5D)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return fallback\n",
    "\n",
    "def tf_profile(model: tf.keras.Model,\n",
    "               input_shape=None,\n",
    "               device=\"/GPU:0\",\n",
    "               warmup=3, runs=5):\n",
    "    # Input shape\n",
    "    if input_shape is None:\n",
    "        input_shape = _tf_input_shape_from_model(model)\n",
    "\n",
    "    # Determine channels-last vs channels-first from shape\n",
    "    # Expect either (B,D,H,W,C) or (B,C,D,H,W)\n",
    "    if len(input_shape) != 5:\n",
    "        raise ValueError(f\"TF model expected 5D input, got {input_shape}\")\n",
    "    if input_shape[-1] in (1,2,3,4):\n",
    "        layout = \"channels_last\"\n",
    "    else:\n",
    "        layout = \"channels_first\"\n",
    "\n",
    "    # Build dummy\n",
    "    x_np = np.random.randn(*input_shape).astype(np.float32)\n",
    "    x_tf = tf.constant(x_np)\n",
    "\n",
    "    # Params\n",
    "    try:\n",
    "        params = int(model.count_params())\n",
    "    except Exception:\n",
    "        params = float(\"nan\")\n",
    "\n",
    "    # FLOPs via TF profiler (best effort)\n",
    "    def _flops_estimate_keras(model, sample):\n",
    "        try:\n",
    "            @tf.function(jit_compile=False)\n",
    "            def _call(inp):\n",
    "                return model(inp, training=False)\n",
    "\n",
    "            concrete = _call.get_concrete_function(sample)\n",
    "            frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(concrete)\n",
    "            # Use TF v1 profiler on graph_def\n",
    "            opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "            flops = tf.compat.v1.profiler.profile(\n",
    "                graph=frozen_func.graph,\n",
    "                options=opts\n",
    "            )\n",
    "            return float(flops.total_float_ops) if flops is not None else float(\"nan\")\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] TF FLOPs profiling failed: {e}\")\n",
    "            return float(\"nan\")\n",
    "\n",
    "    flops_total = _flops_estimate_keras(model, x_tf)  # raw FLOPs (approx)\n",
    "    flops_str = fmt_si(flops_total, kind=\"count\") if not np.isnan(flops_total) else \"NaN\"\n",
    "    macs_str  = \"NaN\"  # TF v1 profiler reports FLOPs, not MACs\n",
    "\n",
    "    # GPU memory (best effort; only works on TF>=2.9 and with GPU)\n",
    "    mem_mb = float(\"nan\")\n",
    "    try:\n",
    "        gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "        if gpus:\n",
    "            # Clear peak then run once\n",
    "            # Note: TF doesn't expose a reset; we sample before/after instead.\n",
    "            _ = model(x_tf, training=False)\n",
    "            info = tf.config.experimental.get_memory_info(\"GPU:0\")\n",
    "            # peak memory since the start of program in bytes\n",
    "            mem_mb = info.get(\"peak\", np.nan) / (1024**2)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] TF memory query failed: {e}\")\n",
    "\n",
    "    # Latency\n",
    "    try:\n",
    "        for _ in range(warmup):\n",
    "            _ = model(x_tf, training=False)\n",
    "        t0 = time.time()\n",
    "        for _ in range(runs):\n",
    "            _ = model(x_tf, training=False)\n",
    "        lat_s = (time.time() - t0) / runs\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] TF latency failed: {e}\")\n",
    "        lat_s = float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"Params (#)\": params,\n",
    "        \"FLOPs\": flops_str,\n",
    "        \"MACs\": macs_str,\n",
    "        \"Inference Memory (MB)\": mem_mb,\n",
    "        \"Latency per Inference (s)\": lat_s,\n",
    "        \"layout\": layout,\n",
    "        \"input_shape_used\": input_shape,\n",
    "    }\n",
    "\n",
    "# ========= Run all & pretty print =========\n",
    "torch_models = {\n",
    "    \"V-NET (UNet3D)\": unet_model,\n",
    "    \"ViT (3D Transformer)\": vit_model,\n",
    "}\n",
    "tf_models = {\n",
    "    \"Base Model (TF)\": base_model_tf,\n",
    "}\n",
    "\n",
    "torch_rows = []\n",
    "for name, m in torch_models.items():\n",
    "    res = torch_profile(m, input_shape=(1,2,128,128,128), device=\"cuda\")\n",
    "    torch_rows.append({\"Model\": name, **res})\n",
    "\n",
    "tf_rows = []\n",
    "for name, m in tf_models.items():\n",
    "    # If your TF model expects (B,2,128,128,128) (channels-first), pass that here:\n",
    "    # tf_input = (1,2,128,128,128)\n",
    "    res = tf_profile(m, input_shape=None, device=\"/GPU:0\")\n",
    "    tf_rows.append({\"Model\": name, **res})\n",
    "\n",
    "df_all = pd.DataFrame(torch_rows + tf_rows,\n",
    "                      columns=[\"Model\",\"Params (#)\",\"FLOPs\",\"MACs\",\"Inference Memory (MB)\",\"Latency per Inference (s)\"])\n",
    "\n",
    "# Human-readable view\n",
    "df_pretty = pd.DataFrame({\n",
    "    \"Model\": df_all[\"Model\"],\n",
    "    \"Params\": [fmt_params(x) if isinstance(x,(int,float)) else x for x in df_all[\"Params (#)\"]],\n",
    "    \"FLOPs\":  df_all[\"FLOPs\"],\n",
    "    \"MACs\":   df_all[\"MACs\"],\n",
    "    \"Mem\":    [fmt_si(x, \"mem\") if isinstance(x,(int,float)) else x for x in df_all[\"Inference Memory (MB)\"]],\n",
    "    \"Latency\": [fmt_si(x, \"time_ms\") if isinstance(x,(int,float)) else x for x in df_all[\"Latency per Inference (s)\"]],\n",
    "})\n",
    "\n",
    "print(\"\\n=== Model Complexity & Practical Usability (All) ===\\n\")\n",
    "print(df_pretty.to_string(index=False))\n",
    "\n",
    "df_all.to_csv(\"model_complexity_summary_all.csv\", index=False)\n",
    "print(\"\\nSaved → model_complexity_summary_all.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09accf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 15:26:24.648910: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2025-11-12 15:26:24.649139: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2025-11-12 15:26:24.658090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20533 MB memory:  -> device: 0, name: NVIDIA A10, pci bus id: 0000:48:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1839.50b flops)\n",
      "  model_1/conv3d_18/Conv3D (695.78b/695.78b flops)\n",
      "  model_1/conv3d_17/Conv3D (347.89b/347.89b flops)\n",
      "  model_1/conv3d_11/Conv3D (268.44b/268.44b flops)\n",
      "  model_1/conv3d_16/Conv3D (173.95b/173.95b flops)\n",
      "  model_1/conv3d_12/Conv3D (134.22b/134.22b flops)\n",
      "  model_1/conv3d_15/Conv3D (86.97b/86.97b flops)\n",
      "  model_1/conv3d_13/Conv3D (67.11b/67.11b flops)\n",
      "  model_1/conv3d_14/Conv3D (33.55b/33.55b flops)\n",
      "  model_1/conv3d_10/Conv3D (16.78b/16.78b flops)\n",
      "  model_1/conv3d_19/Conv3D (14.72b/14.72b flops)\n",
      "  model_1/conv3d_10/BiasAdd (33.55m/33.55m flops)\n",
      "  model_1/conv3d_18/BiasAdd (33.55m/33.55m flops)\n",
      "  model_1/conv3d_11/BiasAdd (8.39m/8.39m flops)\n",
      "  model_1/conv3d_17/BiasAdd (8.39m/8.39m flops)\n",
      "  model_1/conv3d_12/BiasAdd (2.10m/2.10m flops)\n",
      "  model_1/conv3d_16/BiasAdd (2.10m/2.10m flops)\n",
      "  model_1/conv3d_19/BiasAdd (2.10m/2.10m flops)\n",
      "  model_1/conv3d_13/BiasAdd (524.29k/524.29k flops)\n",
      "  model_1/conv3d_15/BiasAdd (524.29k/524.29k flops)\n",
      "  model_1/conv3d_14/BiasAdd (131.07k/131.07k flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=== Model Complexity & Practical Usability (Including cGAN) ===\n",
      "\n",
      "                       Model   Params    FLOPs     MACs        Mem    Latency\n",
      "              V-NET (UNet3D)  28.824M 121.235G  60.617G 937.347 MB  30.643 ms\n",
      "        ViT (3D Transformer)  23.502M   2.282T   1.141T     2.994K 119.528 ms\n",
      "cGAN (Pix2PixCC3D-Generator)  27.808M 953.571G 476.785G     1.100K 211.507 ms\n",
      "             Base Model (TF) 461.007M   1.840T      NaN     6.002K 248.639 ms\n",
      "\n",
      "Saved → model_complexity_summary_all_with_cgan.csv\n"
     ]
    }
   ],
   "source": [
    "# === Next cell: robust cGAN load (fix relative-import error) + clean FLOPs warnings + re-run table ===\n",
    "# Assumes previous cells defined:\n",
    "#   - load_symbol_from_file(), fmt_si(), torch_profile(), tf_profile()\n",
    "#   - `unet_model`, `vit_model`, `base_model_tf`\n",
    "#   - `GAN_PATH` (string path to .../src/model.py), `SYM_GAN`\n",
    "#   - CUDA/TF already set up\n",
    "\n",
    "import os, math, time, types, importlib.util, sys, logging\n",
    "import torch\n",
    "import pandas as pd\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 0) Quiet THOP's \"Upsample: trilinear not implemented\" warnings in logs\n",
    "#    (FLOPs for Upsample are treated as ~0; this only suppresses noisy logs)\n",
    "# ----------------------------------------------------------------------\n",
    "try:\n",
    "    import thop\n",
    "    logging.getLogger().setLevel(logging.ERROR)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1) Loader that respects relative imports in GAN (\".utils\") by creating\n",
    "#    a synthetic package name and loading utils + model under that package.\n",
    "# ----------------------------------------------------------------------\n",
    "def load_symbol_with_package(model_path: str, symbol_name: str, pkg: str = \"cganpkg\"):\n",
    "    \"\"\"\n",
    "    Load `symbol_name` from a Python file that uses relative imports like `from .utils import ...`.\n",
    "\n",
    "    It:\n",
    "      - infers the sibling utils.py in the same directory,\n",
    "      - loads it as `<pkg>.utils`,\n",
    "      - loads the model.py as `<pkg>.model`,\n",
    "      - then returns `getattr(<pkg>.model, symbol_name)`.\n",
    "    \"\"\"\n",
    "    model_path = os.path.abspath(model_path)\n",
    "    src_dir    = os.path.dirname(model_path)\n",
    "    utils_path = os.path.join(src_dir, \"utils.py\")\n",
    "\n",
    "    if not os.path.isfile(model_path):\n",
    "        raise ImportError(f\"[cGAN] model file not found: {model_path}\")\n",
    "    if not os.path.isfile(utils_path):\n",
    "        raise ImportError(f\"[cGAN] utils file not found (required for relative import): {utils_path}\")\n",
    "\n",
    "    # Load <pkg>.utils\n",
    "    utils_name = f\"{pkg}.utils\"\n",
    "    if utils_name in sys.modules:\n",
    "        utils_mod = sys.modules[utils_name]\n",
    "    else:\n",
    "        utils_spec = importlib.util.spec_from_file_location(utils_name, utils_path)\n",
    "        if utils_spec is None or utils_spec.loader is None:\n",
    "            raise ImportError(f\"[cGAN] Cannot create spec for utils: {utils_path}\")\n",
    "        utils_mod = importlib.util.module_from_spec(utils_spec)\n",
    "        sys.modules[utils_name] = utils_mod\n",
    "        utils_spec.loader.exec_module(utils_mod)  # type: ignore\n",
    "\n",
    "    # Load <pkg>.model\n",
    "    model_name = f\"{pkg}.model\"\n",
    "    model_spec = importlib.util.spec_from_file_location(model_name, model_path)\n",
    "    if model_spec is None or model_spec.loader is None:\n",
    "        raise ImportError(f\"[cGAN] Cannot create spec for model: {model_path}\")\n",
    "    model_mod = importlib.util.module_from_spec(model_spec)\n",
    "    # Hint package context so that `.utils` resolves to `<pkg>.utils`\n",
    "    model_mod.__package__ = pkg  # crucial for relative imports inside model.py\n",
    "    sys.modules[model_name] = model_mod\n",
    "    model_spec.loader.exec_module(model_mod)  # type: ignore\n",
    "\n",
    "    if not hasattr(model_mod, symbol_name):\n",
    "        raise ImportError(f\"[cGAN] `{symbol_name}` not found in model module at {model_path}\")\n",
    "\n",
    "    return getattr(model_mod, symbol_name)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2) Load cGAN Generator class (fixes: \"attempted relative import with no known parent package\")\n",
    "# ----------------------------------------------------------------------\n",
    "try:\n",
    "    GeneratorPix2PixCC3D = load_symbol_with_package(GAN_PATH, SYM_GAN, pkg=\"pix2pixcc3d\")\n",
    "except Exception as e:\n",
    "    raise ImportError(f\"[cGAN] Failed to load `{SYM_GAN}` from {GAN_PATH}: {e}\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3) Instantiate cGAN Generator\n",
    "#    NOTE: set trans_conv=True to avoid Upsample(trilinear) in FLOPs (cleaner profiling)\n",
    "# ----------------------------------------------------------------------\n",
    "# --- cGAN 옵션만 수정: norm_type을 'InstanceNorm3d'로 지정 ---\n",
    "# ✅ 최종 권장 옵션 (두 곳 수정됨)\n",
    "gan_opt = SimpleNamespace(\n",
    "    input_ch=2, target_ch=1,\n",
    "    n_gf=32, n_df=32,\n",
    "    n_downsample=3, n_residual=6,\n",
    "    norm_type='InstanceNorm3d',   # <- 'instance' 대신 정확한 이름\n",
    "    padding_type='reflection',    # <- 'reflect' 대신 'reflection'\n",
    "    trans_conv=True,              # (THOP trilinear 경고 피하려면 True 유지)\n",
    "    n_D=3, ch_balance=0.0,\n",
    "    lambda_LSGAN=1.0, lambda_FM=10.0, lambda_CC=5.0,\n",
    "    n_CC=2, ccc=True, eps=1e-8,\n",
    "    gpu_ids=0, data_type=32\n",
    ")\n",
    "gan_model = GeneratorPix2PixCC3D(gan_opt)\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 4) Build dicts and profile everything again\n",
    "# ----------------------------------------------------------------------\n",
    "torch_models = {\n",
    "    \"V-NET (UNet3D)\": unet_model,\n",
    "    \"ViT (3D Transformer)\": vit_model,\n",
    "    \"cGAN (Pix2PixCC3D-Generator)\": gan_model,\n",
    "}\n",
    "tf_models = {\n",
    "    \"Base Model (TF)\": base_model_tf,\n",
    "}\n",
    "\n",
    "# Reuse torch_profile/tf_profile from previous cells\n",
    "torch_rows = []\n",
    "for name, m in torch_models.items():\n",
    "    res = torch_profile(m, input_shape=(1,2,128,128,128), device=\"cuda\")\n",
    "    torch_rows.append({\"Model\": name, **res})\n",
    "\n",
    "tf_rows = []\n",
    "for name, m in tf_models.items():\n",
    "    res = tf_profile(m, input_shape=None, device=\"/GPU:0\")\n",
    "    tf_rows.append({\n",
    "        \"Model\": name,\n",
    "        \"Params (#)\": res.get(\"Params (#)\"),\n",
    "        \"FLOPs\":       res.get(\"FLOPs\"),\n",
    "        \"MACs\":        res.get(\"MACs\"),\n",
    "        \"Inference Memory (MB)\": res.get(\"Inference Memory (MB)\"),\n",
    "        \"Latency per Inference (s)\": res.get(\"Latency per Inference (s)\"),\n",
    "    })\n",
    "\n",
    "df_all = pd.DataFrame(\n",
    "    torch_rows + tf_rows,\n",
    "    columns=[\"Model\",\"Params (#)\",\"FLOPs\",\"MACs\",\"Inference Memory (MB)\",\"Latency per Inference (s)\"]\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 5) Pretty print + save\n",
    "# ----------------------------------------------------------------------\n",
    "def _fmt_params(n):\n",
    "    if n is None or (isinstance(n, float) and (math.isnan(n) or math.isinf(n))):\n",
    "        return \"NaN\"\n",
    "    if n >= 1e9: return f\"{n/1e9:.3f}B\"\n",
    "    if n >= 1e6: return f\"{n/1e6:.3f}M\"\n",
    "    return f\"{n:,}\"\n",
    "\n",
    "df_pretty = pd.DataFrame({\n",
    "    \"Model\": df_all[\"Model\"],\n",
    "    \"Params\": [ _fmt_params(x) if isinstance(x,(int,float)) else x for x in df_all[\"Params (#)\"] ],\n",
    "    \"FLOPs\":  df_all[\"FLOPs\"],\n",
    "    \"MACs\":   df_all[\"MACs\"],\n",
    "    \"Mem\":    [ fmt_si(x, \"mem\") if isinstance(x,(int,float)) else x for x in df_all[\"Inference Memory (MB)\"] ],\n",
    "    \"Latency\": [ fmt_si(x, \"time_ms\") if isinstance(x,(int,float)) else x for x in df_all[\"Latency per Inference (s)\"] ],\n",
    "})\n",
    "\n",
    "print(\"\\n=== Model Complexity & Practical Usability (Including cGAN) ===\\n\")\n",
    "print(df_pretty.to_string(index=False))\n",
    "\n",
    "out_csv = \"model_complexity_summary_all_with_cgan.csv\"\n",
    "df_all.to_csv(out_csv, index=False)\n",
    "print(f\"\\nSaved → {out_csv}\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# (Optional) If you still prefer Upsample(trilinear) inside GAN for inference,\n",
    "# set `gan_opt.trans_conv=False` above for the final run; FLOPs will show zeros for Upsample\n",
    "# but latency/memory will still be measured correctly.\n",
    "# ----------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf56a18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Complexity Summary (Including cGAN) ===\n",
      "\n",
      "                       Model Params (#)    FLOPs     MACs Inference Memory (MB) Latency per Inference (s)\n",
      "              V-NET (UNet3D)   28.824 M 121.235G  60.617G                937 MB                  30.64 ms\n",
      "        ViT (3D Transformer)   23.502 M   2.282T   1.141T              2,994 MB                 119.53 ms\n",
      "cGAN (Pix2PixCC3D-Generator)   27.808 M 953.571G 476.785G              1,100 MB                 211.51 ms\n",
      "             Base Model (TF)  461.007 M   1.840T      NaN              6,002 MB                 248.64 ms\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# CSV 경로\n",
    "csv_path = \"/home/mingyeong/GAL2DM_ASIM_VNET/eval/model_complexity_summary_all_with_cgan.csv\"\n",
    "\n",
    "# CSV 읽기\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 숫자 포맷 함수\n",
    "def fmt_params(n):\n",
    "    if isinstance(n, str):\n",
    "        return n\n",
    "    if math.isnan(n):\n",
    "        return \"NaN\"\n",
    "    if n >= 1e9:\n",
    "        return f\"{n/1e9:.3f} B\"\n",
    "    if n >= 1e6:\n",
    "        return f\"{n/1e6:.3f} M\"\n",
    "    if n >= 1e3:\n",
    "        return f\"{n/1e3:.3f} K\"\n",
    "    return f\"{n:.0f}\"\n",
    "\n",
    "def fmt_mem(x):\n",
    "    if isinstance(x, str):\n",
    "        return x\n",
    "    if math.isnan(x):\n",
    "        return \"NaN\"\n",
    "    return f\"{x:,.0f} MB\"\n",
    "\n",
    "def fmt_lat(x):\n",
    "    if isinstance(x, str):\n",
    "        return x\n",
    "    if math.isnan(x):\n",
    "        return \"NaN\"\n",
    "    return f\"{x*1e3:.2f} ms\"\n",
    "\n",
    "# 각 컬럼에 포맷 적용\n",
    "df[\"Params (#)\"] = df[\"Params (#)\"].apply(fmt_params)\n",
    "df[\"Inference Memory (MB)\"] = df[\"Inference Memory (MB)\"].apply(fmt_mem)\n",
    "df[\"Latency per Inference (s)\"] = df[\"Latency per Inference (s)\"].apply(fmt_lat)\n",
    "\n",
    "# 보기 좋은 순서로 정렬\n",
    "order = [\"Model\", \"Params (#)\", \"FLOPs\", \"MACs\", \"Inference Memory (MB)\", \"Latency per Inference (s)\"]\n",
    "df = df[[c for c in order if c in df.columns]]\n",
    "\n",
    "# 출력\n",
    "print(\"\\n=== Model Complexity Summary (Including cGAN) ===\\n\")\n",
    "print(df.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
